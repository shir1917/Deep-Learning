{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Paraphrase.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPaJc/ap1D8FPvY93JdHRl6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srulikbd/Deep-Learning/blob/master/Paraphrase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVx_1_NOXHbD",
        "outputId": "6327100b-9283-4ba9-94ac-5faf03db13ba"
      },
      "source": [
        " \n",
        "!pip install torch==1.7\n",
        "!pip install transformers==3.5\n",
        "!pip install pytorch_lightning==0.7.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.7 in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7) (0.18.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7) (3.7.4.3)\n",
            "Requirement already satisfied: transformers==3.5 in /usr/local/lib/python3.6/dist-packages (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (1.18.5)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (0.9.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (0.1.91)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (3.12.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (0.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.5) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.5) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5) (0.17.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.5) (50.3.2)\n",
            "Requirement already satisfied: pytorch_lightning==0.7.5 in /usr/local/lib/python3.6/dist-packages (0.7.5)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning==0.7.5) (2.3.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning==0.7.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning==0.7.5) (1.18.5)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning==0.7.5) (0.18.2)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning==0.7.5) (1.7.0+cu101)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (3.3.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (50.3.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.10.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.33.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.4.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.15.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_lightning==0.7.5) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_lightning==0.7.5) (0.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch_lightning==0.7.5) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.7.5) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (0.2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwqj2uZzAGjq",
        "outputId": "8b766a7d-70cf-4fe8-ebef-eea0cf2a284a"
      },
      "source": [
        "import torch\n",
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_paraphraser')\n",
        "tokenizer = T5Tokenizer.from_pretrained('ramsrigouthamg/t5_paraphraser')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print (\"device \",device)\n",
        "model = model.to(device)\n",
        "\n",
        "sentence = \"“Georgia is not the only state that pushed through these last minute rules changes before the presidential election.” @marthamaccallum They forgot about our Constitution!\"\n",
        "# sentence = \"What are the ingredients required to bake a perfect cake?\"\n",
        "# sentence = \"What is the best possible approach to learn aeronautical engineering?\"\n",
        "# sentence = \"Do apples taste better than oranges in general?\"\n",
        "\n",
        "\n",
        "text =  \"paraphrase: \" + sentence + \" </s>\"\n",
        "\n",
        "\n",
        "max_len = 256\n",
        "\n",
        "encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
        "input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "\n",
        "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
        "beam_outputs = model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    do_sample=True,\n",
        "    max_length=256,\n",
        "    top_k=120,\n",
        "    top_p=0.98,\n",
        "    early_stopping=True,\n",
        "    num_return_sequences=10\n",
        ")\n",
        "\n",
        "\n",
        "print (\"\\nOriginal Question ::\")\n",
        "print (sentence)\n",
        "print (\"\\n\")\n",
        "print (\"Paraphrased Questions :: \")\n",
        "final_outputs =[]\n",
        "for beam_output in beam_outputs:\n",
        "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
        "        final_outputs.append(sent)\n",
        "\n",
        "for i, final_output in enumerate(final_outputs):\n",
        "    print(\"{}: {}\".format(i, final_output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device  cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_t5.py:184: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated eos tokens being added.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original Question ::\n",
            "“Georgia is not the only state that pushed through these last minute rules changes before the presidential election.” @marthamaccallum They forgot about our Constitution!\n",
            "\n",
            "\n",
            "Paraphrased Questions :: \n",
            "0: How did Georgia get on my list with the last minute rules change before the election?\n",
            "1: Because Georgia is a state, it is very unusual to see states putting in last minute changes so before the 2016 election. I'm sorry, Virginia, who hasn't complied with the first amendments?\n",
            "2: I know Georgia was upset by last minute change in rules that President Obama allowed before the election. I'd feel sorry for Georgia’s attitude. Are there any other states that have done this before?\n",
            "3: What are some states that forgot about our Constitution and their rules before the election?\n",
            "4: Is Georgia the only state in the world that pushed through these last minute rules changes for the 2016 presidential election?\n",
            "5: \"Georgia is not the only state that pushed through these last minute rule changes before the presidential election.\" @marthamaccallum\n",
            "6: #Georgia is not the only state that pushed through these last minute rules changes before the presidential election. They forgot about our Constitution!\n",
            "7: Why did Georgia not adopt laws before the presidential election?\n",
            "8: Why did Georgia rig the Georgia Constitution during the 2012 Presidential election?\n",
            "9: “Georgia is not the only state that pushed through these last minute rules changes before the presidential election.” @marthamaccallum Their Constitution didn’t exist!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XldanKN2fYeo",
        "outputId": "c0fb417d-7d9f-450d-9b71-66e6cbdd5fb3"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")  \n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print (\"device \",device)\n",
        "model = model.to(device)\n",
        "sentence = \"Georgia is not the only state that pushed through these last minute rules changes before the presidential election\"\n",
        "\n",
        "text =  \"paraphrase: \" + sentence + \" </s>\"\n",
        "\n",
        "encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
        "input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n",
        "\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    max_length=256,\n",
        "    do_sample=True,\n",
        "    top_k=120,\n",
        "    top_p=0.95,\n",
        "    early_stopping=True,\n",
        "    num_return_sequences=5\n",
        ")\n",
        "\n",
        "for output in outputs:\n",
        "    line = tokenizer.decode(output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device  cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_t5.py:184: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated eos tokens being added.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Georgia is not the only state that pushed through these last minute rules changes before the presidential election.\n",
            "Georgia is not the only state that pushed these last minute rules changes before the presidential election to the public.\n",
            "Georgia is not the only state that pushed these last-minute rule changes before the presidential election.\n",
            "Georgia is not the only state that has pushed through these last minute rule changes before the presidential election\n",
            "Georgia is not the only state that pushed these last minute changes to the rules before the presidential election.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv-hiSgGCQ8Y",
        "outputId": "2060d1a7-22ad-4a4d-dbe4-0f34ff381958"
      },
      "source": [
        "import torch\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "model_name = 'tuner007/pegasus_paraphrase'\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "\n",
        "def get_response(input_text,num_return_sequences):\n",
        "  batch = tokenizer.prepare_seq2seq_batch([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
        "  translated = model.generate(**batch,max_length=120,num_beams=10, num_return_sequences=num_return_sequences, temperature=1.0)\n",
        "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "  return tgt_text\n",
        "\n",
        "context = \"Still the greatest President in the history of our once Great country. MAGA NOT GIVING UP! He was born to run, don't belong to anyone. He don't need to be loved by you. Fire in His lungs, can't bite the devil on His tongue. Because He is a big macho dragon man.\"\n",
        "get_response(context,10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['He is the greatest President in the history of our country.',\n",
              " \"He doesn't need to be loved by you, he was born to run.\",\n",
              " 'He is the greatest President in the history of the country.',\n",
              " 'He is the greatest President in the history of the United States.',\n",
              " 'He is still the greatest President in the history of our country.',\n",
              " \"He doesn't need to be loved by you, he was born to run, and can't bite the devil.\",\n",
              " \"He's the greatest President in the history of our country.\",\n",
              " \"He doesn't need to be loved by you, he was born to run, and he can't bite the devil.\",\n",
              " \"He's the greatest President in the history of the country.\",\n",
              " \"He's still the greatest President in the history of our country.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    }
  ]
}